# Initialization
%matplotlib inline
from warnings import filterwarnings
filterwarnings("ignore")


# %load ml01.py
from sklearn.datasets import make_classification
# Create a synthetic dataset for classification
X, y = make_classification(n_samples=100, n_features=20, 
                           n_informative=2, n_redundant=2, 
                           n_classes=2, random_state=42)
# X contains the feature matrix
# y contains the target labels


X.shape, y.shape


# %load ml02.py
from sklearn.datasets import make_blobs
# Create a synthetic dataset using make_blobs
X, y = make_blobs(n_samples=100, centers=3, 
                  n_features=2, random_state=42)
# X contains the feature matrix
# y contains the cluster labels



X.shape, y.shape


# %load ml03.py
# Import the necessary module from scikit-learn
from sklearn.datasets import load_iris
# Load the Iris dataset
dataset = load_iris()
# Extract features and target variables
X = dataset.data
y = dataset.target
# Display feature names and target names
print("Feature Names:", dataset.feature_names)
print("Target Names:", dataset.target_names)


X.shape, y.shape


# %load ml04.py
# Use read_csv() to load data from CSV file
from pandas import read_csv
header = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']
df = read_csv('data/pima-indians-diabetes.data.csv', names=header)
print(df.head(3)) # print the first 3 rows of data
# separate data into features and target
X = df.drop(columns=['class'])
y = df['class']
print(df.shape, X.shape, y.shape) # print the dimension of the dataframe, X & y



# %load ml05.py
# Print statistical summary and class breakdown
from pandas import read_csv
header = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']
df = read_csv('data/pima-indians-diabetes.data.csv', names=header)
print(df.describe())  # print the statistical summary of the data
class_counts = df.groupby('class').size()
print(class_counts)  # print the class breakdown of the data


# %load ml06.py
import matplotlib.pyplot as plt
import pandas as pd
# Load the dataset
header = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']
df = pd.read_csv('data/pima-indians-diabetes.data.csv', names=header)
# Histogram
df['age'].hist()
plt.title('Age Distribution')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.show()

# Plotting boxplots for the features
df.boxplot(column=['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age'])
plt.title('Box plot of Mass and Age')
plt.show()

# Scatter Plot
df.plot.scatter(x='age', y='mass')
plt.title('Scatter plot of Age vs Mass')
plt.xlabel('Age')
plt.ylabel('Mass')
plt.show()

# Correlation Heatmap
plt.figure(figsize=(10, 6))
plt.imshow(df.corr(), cmap='hot', interpolation='nearest')
plt.colorbar()
plt.title('Correlation Heatmap')
plt.show()

# Density Plot
df['mass'].plot(kind='density')
plt.title('Density Plot of Mass')
plt.xlabel('Mass')
plt.show()

# Pie Chart
df['class'].value_counts().plot(kind='pie', autopct='%.1f%%')
plt.title('Class Distribution')
plt.show()



# %load ml07.py
import pandas as pd
import numpy as np

# Load the dataset
df = pd.read_csv('data/data_cleaning.csv')
print(df)

# Remove duplicated rows
df = df.drop_duplicates()
# Remove duplicated columns
df = df.T.drop_duplicates().T
print(df)

# Mark missing values as NaN
df = df.apply(pd.to_numeric, errors='coerce')
print(df)
print(df.info())

# Remove columns with no variance
variance = df.var()
columns_to_drop = variance[variance == 0].index
df = df.drop(columns=columns_to_drop)
print(df)

# Calculate the number of outliers for each feature
outliers = {}
for column in df.columns[:-1]:  # Excluding the last column (target)
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers[column] = df[(df[column] < lower_bound) | (df[column] > upper_bound)].shape[0]
# Print the number of outliers for each feature
for column in outliers:
    print(f"Feature â€˜{column}' has {outliers[column]} outliers")

# Clip outliers
for column in df.columns[:-1]:
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df[column] = df[column].clip(lower_bound, upper_bound)
print(df)



# %load ml08.py
import pandas as pd
import numpy as np
df = pd.DataFrame({'Age': [17, 23, 0, 38, 54, 67, 32],
                   'Height': [160, 172, 150, 165, 163, 158, 175],
                   'Weight':[50, 68, 43, 52, 47, 49, 0]})
df = df.replace({0: np.nan}) # replace missing value (0) with NaN
print(df)
print(df.isnull().sum())
df = df.dropna(axis=0) # drop rows with NaN
print(df)



# %load ml09.py
import pandas as pd
import numpy as np
df = pd.DataFrame({'Age': [17, 23, 0, 38, 54, 67, 32],
                   'Height': [160, 172, 150, 165, 163, 158, 175],
                   'Weight':[50, 68, 43, 52, 47, 49, 0]})
df = df.replace({0: np.nan})
df['Age'] = df['Age'].fillna(df['Age'].median()) # replace NaN with median
df['Weight'] = df['Weight'].fillna(df['Weight'].mean()) # replace NaN with mean
print(df)



# %load ml10.py
# Handling categorical data
import pandas as pd
df = pd.DataFrame({'year':[2015, 2017, 2013, 2018, 2020],
                   'make':['Toyota', 'Honda', 'Perodua', 'Hyundai', 'Toyota'],
                   'engine':[1.5, 1.8, 1.3, 1.6, 1.8],
                   'review':['moderate', 'good', 'poor', 'moderate', 'good']})
mapping = {'poor':1, 'moderate':2, 'good':3}
df['review'] = df['review'].map(mapping) # encode ordinal data
df = pd.get_dummies(df) # encode nominal data
print(df)




